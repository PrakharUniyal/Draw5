{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from random import randint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(dir, files, reshaped):\n",
    "    \"Load .npy or .npz files from disk and return them as numpy arrays. \\\n",
    "    Takes in a list of filenames and returns a list of numpy arrays.\"\n",
    "\n",
    "    data = []\n",
    "    for file in files:\n",
    "        f = np.load(dir + file)\n",
    "        if reshaped:\n",
    "            new_f = []\n",
    "            for i in range(len(f)):\n",
    "                x = np.reshape(f[i], (28, 28))\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = np.reshape(f[i], (28, 28, 1))\n",
    "                new_f.append(x)\n",
    "            f = new_f\n",
    "        data.append(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    \"Takes a list or a list of lists and returns its normalized form\"\n",
    "\n",
    "    return np.interp(data, [0, 255], [-1, 1])\n",
    "\n",
    "\n",
    "def denormalize(data):\n",
    "    \"Takes a list or a list of lists and returns its denormalized form\"\n",
    "\n",
    "    return np.interp(data, [-1, 1], [0, 255])\n",
    "\n",
    "\n",
    "def visualize(array):\n",
    "    \"Visulaze a 2D array as an Image\"\n",
    "\n",
    "    img = Image.fromarray(array)\n",
    "    img.show(title=\"Visulizing array\")\n",
    "\n",
    "\n",
    "def set_limit(arrays, n):\n",
    "    \"Limit elements from each array up to n elements and return a single list\"\n",
    "    new = []\n",
    "    for array in arrays:\n",
    "        i = 0\n",
    "        for item in array:\n",
    "            if i == n:\n",
    "                break\n",
    "            new.append(item)\n",
    "            i += 1\n",
    "    return new\n",
    "\n",
    "\n",
    "def make_labels(N1, N2):\n",
    "    \"make labels from 0 to N1, each repeated N2 times\"\n",
    "    labels = []\n",
    "    for i in range(N1):\n",
    "        labels += [i] * N2\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=600, activation='relu', input_dim=784))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units=400, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units=25, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units=classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "3800/3800 [==============================] - 3s 905us/step - loss: 0.8730 - acc: 0.6429\n",
      "Epoch 2/20\n",
      "3800/3800 [==============================] - 2s 447us/step - loss: 0.5070 - acc: 0.8374\n",
      "Epoch 3/20\n",
      "3800/3800 [==============================] - 2s 464us/step - loss: 0.4444 - acc: 0.8621\n",
      "Epoch 4/20\n",
      "3800/3800 [==============================] - 2s 470us/step - loss: 0.3686 - acc: 0.8866\n",
      "Epoch 5/20\n",
      "3800/3800 [==============================] - 2s 450us/step - loss: 0.3627 - acc: 0.8921\n",
      "Epoch 6/20\n",
      "3800/3800 [==============================] - 2s 453us/step - loss: 0.3287 - acc: 0.8992\n",
      "Epoch 7/20\n",
      "3800/3800 [==============================] - 2s 461us/step - loss: 0.2885 - acc: 0.9113\n",
      "Epoch 8/20\n",
      "3800/3800 [==============================] - 2s 468us/step - loss: 0.2797 - acc: 0.9182\n",
      "Epoch 9/20\n",
      "3800/3800 [==============================] - 2s 481us/step - loss: 0.2419 - acc: 0.9263\n",
      "Epoch 10/20\n",
      "3800/3800 [==============================] - 2s 465us/step - loss: 0.2383 - acc: 0.9316\n",
      "Epoch 11/20\n",
      "3800/3800 [==============================] - 2s 462us/step - loss: 0.2227 - acc: 0.9284\n",
      "Epoch 12/20\n",
      "3800/3800 [==============================] - 2s 464us/step - loss: 0.1925 - acc: 0.9408\n",
      "Epoch 13/20\n",
      "3800/3800 [==============================] - 2s 473us/step - loss: 0.1789 - acc: 0.9418\n",
      "Epoch 14/20\n",
      "3800/3800 [==============================] - 2s 469us/step - loss: 0.1988 - acc: 0.9371\n",
      "Epoch 15/20\n",
      "3800/3800 [==============================] - 2s 487us/step - loss: 0.1751 - acc: 0.9458\n",
      "Epoch 16/20\n",
      "3800/3800 [==============================] - 2s 471us/step - loss: 0.1536 - acc: 0.9516\n",
      "Epoch 17/20\n",
      "3800/3800 [==============================] - 2s 533us/step - loss: 0.1498 - acc: 0.9534\n",
      "Epoch 18/20\n",
      "3800/3800 [==============================] - 2s 538us/step - loss: 0.1500 - acc: 0.9516\n",
      "Epoch 19/20\n",
      "3800/3800 [==============================] - 2s 523us/step - loss: 0.1374 - acc: 0.9568\n",
      "Epoch 20/20\n",
      "3800/3800 [==============================] - 2s 552us/step - loss: 0.1335 - acc: 0.9576\n",
      "Training complete\n",
      "Evaluating model\n",
      "Accuracy:  93.0\n"
     ]
    }
   ],
   "source": [
    "# define some constants\n",
    "N_FRUITS = 4\n",
    "FRUITS = {0: \"Apple\", 1: \"Banana\", 2: \"Grape\", 3: \"Pineapple\"}\n",
    "\n",
    "# number of samples to take in each class\n",
    "N = 1000\n",
    "\n",
    "# some other constants\n",
    "N_EPOCHS = 20\n",
    "\n",
    "# data files in the same order as defined in FRUITS\n",
    "files = [\"apple.npy\", \"banana.npy\", \"grapes.npy\", \"pineapple.npy\"]\n",
    "fruits = load(\"data/\", files, reshaped=False)\n",
    "\n",
    "# limit no of samples in each class to N\n",
    "fruits = set_limit(fruits, N)\n",
    "\n",
    "# normalize the values\n",
    "fruits = list(map(normalize, fruits))\n",
    "\n",
    "# define the labels\n",
    "labels = make_labels(N_FRUITS, N)\n",
    "print(fruits)\n",
    "\n",
    "# prepare the data\n",
    "x_train, x_test, y_train, y_test = tts(fruits, labels, test_size=0.05)\n",
    "\n",
    "# one hot encoding\n",
    "Y_train = np_utils.to_categorical(y_train, N_FRUITS)\n",
    "Y_test = np_utils.to_categorical(y_test, N_FRUITS)\n",
    "\n",
    "# use our custom designed MLP model\n",
    "model = mlp(classes=N_FRUITS)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Training commenced\")\n",
    "\n",
    "model.fit(np.array(x_train), np.array(Y_train), batch_size=32, epochs=N_EPOCHS, verbose=1)\n",
    "\n",
    "print(\"Training complete\")\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "preds = model.predict(np.array(x_test))\n",
    "\n",
    "score = 0\n",
    "for i in range(len(preds)):\n",
    "    if np.argmax(preds[i]) == y_test[i]:\n",
    "        score += 1\n",
    "\n",
    "print(\"Accuracy: \", ((score + 0.0) / len(preds)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
